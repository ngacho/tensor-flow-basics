An Introduction to RELU via [this tutorial](https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/).

In a neural network, the activation function is responsible for transforming the summed weighted input from the node into the activation of the node or output for that input.